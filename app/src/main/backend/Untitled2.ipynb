{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09484af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Définition du chemin vers les fichiers csv\n",
    "path = \"./transactions-ser\"\n",
    "\n",
    "# Récupération de tous les fichiers csv dans le répertoire spécifié\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "# Création d'une liste vide pour stocker tous les dataframes\n",
    "all_df = []\n",
    "# Boucle sur chaque fichier csv pour en créer un dataframe et l'ajouter à la liste\n",
    "for f in all_files:\n",
    "    df = pd.read_csv(f, sep=';')\n",
    "    df['file'] = f.split('/')[-1]\n",
    "    all_df.append(df)\n",
    "    \n",
    "# Concaténation de tous les dataframes en un seul\n",
    "data = pd.concat(all_df, ignore_index=True)\n",
    "merged_df = data.copy()\n",
    "display(merged_df)\n",
    "\n",
    "# Récupèrer que les lignes qui contient appartement et maison et les stockers dans des dataframe séparés\n",
    "df_app = merged_df[merged_df.type_local == 'Appartement']\n",
    "df_mai = merged_df[merged_df.type_local == 'Maison']\n",
    "\n",
    "# Remplacement des valeurs 'None' par NaN dans les deux dataframes\n",
    "df_app=df_app.replace(to_replace='None', value=np.nan)\n",
    "df_mai=df_mai.replace(to_replace='None', value=np.nan)\n",
    "\n",
    "df_mai\n",
    "\n",
    "\n",
    "df_mai = df_mai.dropna(axis=1, how='all')\n",
    "\n",
    "missing_rate = df_mai.isna().sum()/df_mai.shape[0]\n",
    "missing_rate\n",
    "\n",
    "df_mai = df_mai.drop(columns=['adresse_suffixe','lot1_numero', 'lot1_surface_carrez','nature_culture','code_type_local','nombre_lots','code_nature_culture_speciale','adresse_code_voie','code_postal','nature_culture_speciale','id_parcelle','type_local','nom_commune','adresse_nom_voie','id_mutation','file'\n",
    "])\n",
    "\n",
    "df_mai.corr()\n",
    "\n",
    "df_mai = df_mai.drop(columns=['code_commune','code_departement'], axis=1)\n",
    "\n",
    "sns.heatmap(df_mai.corr(), annot=True)\n",
    "df_mai.numero_disposition.unique()\n",
    "\n",
    "df_mai['date_mutation'] = pd.to_datetime(df_mai['date_mutation'])\n",
    "df_mai['annee_mutation'] = df_mai['date_mutation'].dt.year\n",
    "\n",
    "df_mai = df_mai.drop(['date_mutation'], axis=1)\n",
    "\n",
    "df_mai.dtypes\n",
    "\n",
    "code = {'Vente': 0,\n",
    "        'Adjudication': 1,\n",
    "        'Vente en l\\'état futur d\\'achèvement': 2,\n",
    "        'S':0,\n",
    "        'AG':1,\n",
    "        'J':2,\n",
    "        'L':3,\n",
    "        'AB':4,\n",
    "        '1':1,\n",
    "        '2':2,\n",
    "        '000AB': 0, '000AC': 1, '000AD': 2, '000AE': 3, '000AH': 4, '000AI': 5, '000AK': 6, '000AO': 7, '000AP': 8,\n",
    "        '000AR': 9, '000AS': 10, '000AT': 11, '000AV': 12, '000AW': 13, '000AX': 14, '000AY': 15, '000AZ': 16, '000BC': 17,\n",
    "        '000BD': 18, '000BE': 19, '000BH': 20, '000BK': 21, '000BL': 22, '000BM': 23, '000BO': 24, '000BP': 25, '000BR': 26,\n",
    "        '000BS': 27, '000BT': 28, '000BV': 29, '000BW': 30\n",
    "       }\n",
    "\n",
    "for col in df_mai.select_dtypes('object'):\n",
    "    df_mai[col] = df_mai[col].map(code)\n",
    "\n",
    "display(df_mai)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(df_mai.corr(), annot=True)\n",
    "\n",
    "df_mai = df_mai.drop(df_mai[df_mai['valeur_fonciere'] == 3060533.2].index)\n",
    "\n",
    "\n",
    "df_mai = df_mai.drop(df_mai[df_mai['valeur_fonciere'] == 1.0].index)\n",
    "sorted(df_mai.surface_terrain.values)\n",
    "\n",
    "\n",
    "\n",
    "df_mai = df_mai.drop(df_mai[df_mai['nombre_pieces_principales'] == 22.0].index)\n",
    "df_mai = df_mai.drop(columns=['numero_disposition','adresse_numero','section_prefixe','nature_mutation','annee_mutation'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(df_mai.corr(), annot=True)\n",
    "\n",
    "df_mai = df_mai.dropna(subset=['surface_terrain'])\n",
    "\n",
    "df_mai = df_mai.drop(['code_nature_culture'], axis=1)\n",
    "\n",
    "print(nan_counts)\n",
    "\n",
    "df_mai\n",
    "\n",
    "plt.scatter(df_mai.valeur_fonciere, df_mai.surface_reelle_bati)\n",
    "sorted(df_mai.valeur_fonciere, reverse=True)\n",
    "\n",
    "sns.heatmap(df_mai.corr(), annot=True)\n",
    "df_mai.hist()\n",
    "\n",
    "df_mai = df_mai.dropna()\n",
    "df_mai\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline  import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = df_mai.drop(columns=['valeur_fonciere'], axis=1)\n",
    "print(X)\n",
    "y = df_mai['valeur_fonciere']\n",
    "\n",
    "#poly_features = PolynomialFeatures(degree=degree, include_bias = False)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Create a polynomial transformer\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "# Transform the training and test data\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "#poly_features = PolynomialFeatures(degree=degree, include_bias = False)\n",
    "reg = LinearRegression()\n",
    "#X_poly = poly_features.fit_transform(X_train)\n",
    "#X_poly_test = poly_features.fit_transform(X_test)\n",
    "\n",
    "\n",
    "reg.fit(X_train_poly,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "predictions = reg.predict(X_test_poly)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(mse)\n",
    "\n",
    "\n",
    "reg.score(X_test_poly, y_test)\n",
    "\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Polynomial Regression Results')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "\n",
    "results = pd.DataFrame({'True Values': y_test, 'Predicted Values': predictions})\n",
    "\n",
    "# Print the first few rows of the results\n",
    "print(results)\n",
    "\n",
    "scores = cross_val_score(reg, X, y, cv=5)\n",
    "\n",
    "print(np.mean(scores))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
